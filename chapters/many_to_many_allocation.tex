\chapter{تخصیص منابع پردازشی در شبکه اینترنت اشیاء به صورت چند به چند}\label{Chap:many_to_many_allocation}
  \thispagestyle{empty}
  \section{مقدمه}
    در \cref{chap:one_to_one_allocation} تخصیص منابع پردازشی در شبکه اینترنت اشیاء به صورت یک به یک را بررسی کردیم.
    روش معرفی شده در \cref{chap:one_to_one_allocation} برای شرایطی مناسب است که ظرفیت پردازشی مورد نیاز سرویس‌ها با ظرفیت پردازش ارائه شده توسط منابع پردازشی در یک مرتبه باشند.
    واضح است که این شرط در شبکه‌‌های واقعی اینترنت اشیاء قابل قبول نیست.
    علاوه بر این در \cref{chap:one_to_one_allocation} فرض بر این بود که منابع پردازشی ابری با دارای ظرفیت‌های از پیش تعیین شده‌ای هستند که این فرض هم ممکن است در بعضی حالت‌ها قابل قبول نباشد.
    برای حل این مشکلات،‌ در این فصل به بررسی تخصیص منابع پردازشی در شبکه اینترنت اشیاء به صورت چند به چند می‌پردازیم.
    در این نوع از تخصیص منابع، سرویس ها می‌توانند از چند منبع پردازشی برای پردازش داده‌های سنسور‌های خود استفاده کنند و منابع پردازشی هم می‌توانند به چند سرویس اختصاص پیدا کنند.

    در ادامه ابتدا مدل سیستم را توضح می‌دهیم و تفاوت آن را با تخصیص منابع یک به یک مشخص می‌کنیم.
    سپس مانند فصل قبل مسأله تخصیص منابع را به صورت یک مسأله بهینه سازی فرمول بندی می‌کنیم.
    در ادامه یک الگوریتم برای حل این مسأله بهینه سازی معرفی کرده و در انتها نتایج شبیه‌سازی الگوریتم ارائه شده را بررسی می‌کنیم.
  \section{مدل سیستم}
    \begin{figure}[]
      \centerline{\includegraphics[width=15cm]{graphics/many_to_many/system_model}}
      \caption{مدل سیستم}
      \label{fig:many_to_many:system_model}
    \end{figure}
    در این بخش مدل سیستم برای تخصیص منابع پردازشی در شبکه اینترنت اشیاء به صورت چند به چند را توضیح می‌دهیم.
    \cref{fig:many_to_many:system_model} مدل سیستم این فصل را نشان می‌دهد که دارای دو سرویس است.
    سرویس اول از یک منبع پردازشی لبه شبکه به همراه منابع پردازشی ابری و سرویس دوم از دو منبع پردازشی لبه شبکه برای پردازش استفاده می‌کند و یکی از مقاصد نتایج پردازش‌ها ابر است.

    \cref{tbl:many_to_many:notation} به صورت خلاصه پرامتر‌های استفاده شده در این فصل را معرفی می‌کند.
    از تکرار معرفی پارامتر‌هایی که در  \cref{chap:one_to_one_allocation} استفاده شده‌اند، صرف نظر شده‌است.
    \begin{table}[h]
      \caption{نماد‌های استفاده شده در این فصل}
      \begin{tabularx}{\textwidth}{|c|C|} \hline
        نشانه             & توضیح                                                                  \\ \hline
        $I_s$             & مجموعه منابع پردازشی که سرویس $s$ از آن‌ها استفاده می‌کند                \\ \hline
        $I_i$             & مجموعه سرویس‌هایی که منبع پردازشی $i$ به آن‌ها اختصاص پیدا کرده‌است       \\ \hline
        $C_s$             & مجموعه منابع پردازشی که سرویس $s$ می‌تواند از آن‌ها استفاده می‌کند        \\ \hline
        $S_i$             & مجموعه سرویس‌هایی که منبع پردازشی $i$ می‌تواند به آن‌ها اختصاص پیدا کند   \\ \hline
        $Q_s$             & حداکثر تعداد منابع پردازشی که سرویس $s$ مجاز به استفاده از آن‌ها است    \\ \hline
        $Q_i$             & حداکثر تعداد سرویس‌هایی که منبع پردازشی $i$ می‌تواند به آن‌ها اختصاص پیدا کند  \\ \hline
        $d_{i,s}$         & تأخیر منبع پردازشی $i$ برای سرویس $s$                                       \\ \hline
        $d_s^\text{max}$  & بیش‌ترین تاخیر سرویس $s$ بین منابع پردازشی اکه از آن‌ها استفاده می‌کند         \\ \hline
        $r_{i,s}$         & نرخی که سرویس $s$ برای پردازش به منبع پردازشی $i$ می‌فرستد                   \\ \hline
        $u_{i,s}$         & بخشی از ضرفیت پردازشی منبع پردازشی $i$ که توسط سرویس $s$ استفاده می‌شود      \\ \hline
      \end{tabularx}
      \label{tbl:many_to_many:notation}
    \end{table}
    مانند فصل قبل تابع هدف بهینه سازی از دو قسمت تشکیل می‌شود که قسمت اول تابع نرخ انتخابی سرویس‌ها و قسمت دوم مربوط به تاخیر‌ها است
    \begin{equation}
      U_s = \alpha_s \left ( \omega_s f_r(r_s, R_s) + (1-\omega_s) f_d(d_s^\text{max}) \right ) .
    \end{equation}
    در این رابطه $r_s$ مجموع نرخی است که توسط منابع پردازشی برای سرویس $s$ پردازش می‌شود.
    در نتیجه رابطه زیر برای $r_s$ برقرار است
    \begin{equation}
      r_s = \sum_{i \in C_s}^M r_{i,s} .
    \end{equation}
    چون در این فصل فرض بر این است که هر سرویس می‌تواند از چند منبع پردازشی استفاده کند، بیشترین تاخیر منابع پردازشی مورد استفاده سرویس‌ها را به عنوان تاخیر آن سرویس در نظر می‌گیریم.
    اگر فرض کنیم $d_{i,s}$ تاخیر پردازش سرویس $s$ در منبع پردازشی $i$ و $d_s^\text{max}$ بیشترین تاخیر سرویس $s$ باشد، قید زیر برای همه منابع پردازشی انتخاب شده توسط سرویس $s$ باید برقرار باشد
    \begin{equation}\label{eqn:max_delay}
      d_{i,s} < d_s^{max}; \forall s \in S, i \in C_s, \delta_{i,s} = 1.
      این تاخیر مانند فصل قبل برای هر منبع پردازشی از دو قسمت تشکیل شده‌است.
    \end{equation}
    قسمت اول آن مربوط به تاخیر شبکه است که برابر است با زمانی که طول می‌کشد تا نمونه‌ها به منبع پردازشی برسند به علاوه زمانی که طول می‌کشد نتیجه به مقصد برسد.
    قسمت دوم تاخیر پردازش نمونه‌ها در منابع پردازشی است.
    این تاخیر برابر زمانی است که طول می‌کشد تا نمونه‌ها پس از رسیدن به منابع پردازشی، پردازششان پایان یابد.
    همانند فصل قبل برای محاسبه تاخیر پردازشی از تئوری صف استفاده می‌کنیم.
    به دلیل این‌که در این فصل فرض بر این است که منابع پردازشی بین چند سرویس ممکن است تقسیم شوند، از مدل $M/M/1$ استفاده می کنیم.
    در مدل $M/M/1$ میانگین تاخیر $\omega$ از رابطه زیر بدست می‌آید\cite{basic_queueing_sztrik}
    \begin{equation}
      \omega = \frac{1}{\mu-\lambda}.
    \end{equation}
    مانند فصل قبل، ظرفیت پردازشی منبع پردازیش $i$ را با $\varphi_i = \phi_i \nu_i$ است.
    در این فصل متغیر $u_{i,s}$ تعیین می‌کند که چه مقدار از ظریفیت پردازشی منبع پردازشی $i$ تخصیص پیدا می‌کند.
    واضح است که سرویس‌ها نمی‌توانند بیش‌تر از ظرفیت منابع پردازشی از آن‌ها استفاده کنند.
    در نتیجه رابطه زیر برای مقادیر ظرفیت‌های پردازشی تخصیص یافته به سرویس‌ها برای همه منابع پردازشی باید برقرار باشد:
    \begin{equation}
      \sum_{s \in S_i} u_{i,s} \le 1, \forall i \in C.
    \end{equation}
    مانند \cref{chap:one_to_one_allocation} نرخ سرویس برای سرویس $s$ در منبع پردازشی $i$ از رابطه زیر بدست خواهد آمد
    \begin{equation}
      \mu_{i,s} = \frac{\varphi_i}{F_s} u_{i,s} = \zeta_{i,s} u_{i,s}, \forall s \in S, i \in C_s.s
    \end{equation}
    با این تفاسیر رابطه‌ی زیر را برای تاخیر پردازشی سرویس $s$ در منبع پردازشی $i$ وقتی از آن منبع پردازشی استفاده می‌کند می‌توان نوشت
    \begin{equation}
      d_{i,s}^\text{CPU} = \frac{1}{\zeta_{i,s} u_{i,s} - r_s}.
    \end{equation}
    درنتیجه رابطه زیر برای تاخیر سرویس $s$ در منبع پردازشی $i$ برقرار است
    \begin{equation}
      d_{i,s} = d_{i,s}^\text{net} + \frac{1}{\zeta_{i,s} u_{i,s} - r_s}.
    \end{equation}
    این رابطه به عنوان قید در یک بهینه سازی محدب قابل استفاده نیست.
    به همین دلیل سعی میی‌کنیم تغییراتی در آن ایجاد کنیم تا به یک قید محدب تبدیل شود.
    با توجه به وجود $d_{i,s}^\text{max}$ در تابع هدف بهینه سازی، شرایط بیان شده برای تابع $f_d$ در \cref{chap:one_to_one_allocation} و \cref{eqn:max_delay} جزء قید‌های مسئله است، می‌توانیم علامت = را با علامت $\le$ جایگزین کنیم
    \begin{equation}
      \frac{1}{\zeta_{i,s} u_{i,s} - r_s} \le d_{i,s} - d_{i,s}^\text{net}.
    \end{equation}
    چون لگاریتم یک تابع صعودی است، می‌توان بدون مشکلی از دو طرف نامساوی، لگاریتم گرفت و علامت تغییری نکند.
    با لگاریتم گرفتن از طرفین می‌توان قید مناسب برای استفاده در بهینه سازی محدب را بدست آورد.
    \begin{equation}\label{eqn:delay_inequality}
      - \log (\zeta_{i,s} u_{i,s} - r_s) - \log (d_{i,s} - d_{i,s}^\text{net}) \le 0.
    \end{equation}
    دلیل محدب بودن \cref{eqn:delay_inequality} این است که $\zeta_{i,s} u_{i,s} - r_s$ و $d_{i,s} - d_{i,s}^\text{net}$ هر دو تابع محدب هستند.
    همچنین تابع $-\log$ هم یک تابع محدب است.
    با توجه به قضیه ترکیب توابع محدب \cite{boyd2004convex}، \cref{eqn:delay_inequality} یک قید محدب است.

    با توجه به آنچه که تا این جا گفته شد،‌ می‌توان مسئله بهینه سازی را به صورت زیر نوشت
    \begin{subequations}
      \begin{align}
        \underset{r_{i,s}, u_{i,s}, \delta_{i,s}}{\text{maximize}} \qquad & \sum_{s=1}^N \alpha_s \left (\omega_s f_r(r_s, R_s) + (1-\omega_s) f_d(d_{i,s}^\text{max}) \right ) \\
        \text{\lr{subject  to}} \qquad & \nonumber \\
        & r_s = \sum_{i \in S_i} r_{i,s}, \forall s \in S \\
        & 0 \le r_{i,s}, \forall s \in S, i \in C_s \label{eqn:rate_positiveness2} \\
        & r_{i,s} \le \eta \zeta_{i,s} u_{i,s}, \forall s \in S, i \in C_s \label{eqn:rate_saturation2} \\
        & u_{i,s} \le \delta_{i,s}, \forall s \in S, i \in C_s \label{eqn:u_le_delta} \\
        & d_{i,s} \le d_{i,s}^\text{max}, \forall s \in S, i \in C_s, \delta_{i,s}=1 \\
        &- \log \left((\zeta_{i,s} u_{i,s} - r_s) (d_{i,s} - d_{i,s}^\text{net}) \right ) \le 0, \forall s \in S, i\in C_s, \delta_{i,s}=1 \\
        & \sum_{s \in S_i} u_{i,s} \le 1, \forall i \in C \label{eqn:sum_of_utiliztion} \\
        & \sum_{s \in S_i} \delta_{i,s} \le Q_i, \forall i \in C \label{eqn:computation_quota} \\
        & \sum_{i \in C_s} \delta_{i,s} \le Q_s, \forall s \in S \label{eqn:service_quota} \\
        & \delta_{i,s} \in \{0, 1\}, \forall s \in S, i \in C_s
      \end{align}
    \end{subequations}
    در این مسئله
    قید \eqref{eqn:u_le_delta} باعث می‌شود که زمانی که سرویس $s$ از منبع پردازشی $i$ استفاده نمی‌کند $u_{i,s}=0$ باشد و در صورت استفاده $u_{i,s}<1$ باشد.
    باید توجه کرد که قیدهای \cref{eqn:rate_positiveness2} و \cref{eqn:rate_saturation2} باعث می‌شوند که $u_{i,s}$ها مثبت باشند.
    قید \eqref{eqn:sum_of_utiliztion} برای این در بهینه سازی حظور دارد که میزان استفاده از منابع پردازشی نمی‌تواند بیشتر از ظرفیت آن‌ها باشد.
    قید \eqref{eqn:computation_quota} نشان دهنده‌ی حداکثر تعداد سرویس‌هایی است که یک منبع پردازشی می‌تواند به آن‌ها اختصاص پیدا کند.
    قید \eqref{eqn:service_quota} برای محدود کردن حداکثر تعداد منابع پردازشی که یک سرویس می‌تواند استفاده کند است.
    
    مانند فصل قبل، این مسئله بهینه سازی هم یک مسئله برنامه‌ریزی غیرخطی عدد صحیح مخلوط می‌باشد که پیدا کردن جواب بهینه آن ساده نیست.
    به همین دلیل در بخش بعدی یک الگوریتم برای پیدا کردن جواب زیر بهینه آن معرفی می‌کنیم.

  \section{معرفی الگوریتم زیر بهینه}
    این الگوریتم، یک الگوریتم مبتنی بر تکرار است.
    در هر تلکرار الگوریتم، برای هر سرویس، یک تغییر در منابع پردازشی اختصاص یافته به آن سرویس ایجاد می‌کنیم.
    این تغییر می‌توان حذف کردن، اضافه کردن یا جابه‌جایی منابع پردازشی آن سرویس باشد به شرطی که پس از تغییر قید‌های حداکثر تعداد سرویس‌های منابع پردازشی و حداکثر تعداد منابع پردازشی سرویس برقرار باشند.
    این کار را در هر تکرار برای همه‌ی سرویس‌ها انجام می‌دهیم.
    برای هر سرویس هم همه حالت‌های تغییر در یک منبع پردازشی را در نظر می‌گیریم.
    پس انجام این کار، تغییری که بیشترین افزایش را در تابع هدف بهینه‌سازی دارد به تخصیص منابع اعمال می‌کنیم.
    این الگوریتم تا زمانی که مقدار افزایش تابع هدف بهینه سازی بیشتر از مقدار مشخص $\epsilon$ باشد ادامه می‌یابد.
    \cref{alg:suboptimal_algorithm} به صورت خلاصه این الگوریتم را نشان می‌دهد.

    \begin{latin}
      \begin{algorithm}[t]
        \caption{Auction ‌Based Resource Assignment Algorithm}
        \label{alg:suboptimal_algorithm}
        \begin{algorithmic}[1]
          \While{$\nu > \epsilon$}
            \For {$s \in S$}
              \For {$(c_1,c_2) \in (I_s \cup \{\_\}) \times ((C_s \setminus I_s) \cup \{\_\}) $}
                \If{$s \in S_{c_2}$}
                  \State{$I_s \gets (I_s \setminus \{c_1\}) \cup \{c_2\}$}
                  \State{$I_{c_1} \gets I_{c_1} \setminus \{s\}$}
                  \State{$I_{c_2} \gets I_{c_2} \cup \{s\}$}
                  \If{$|I_s| \le Q_s|$ and $|I_{c_2}| \le Q_{c_2}|$}
                    \State{$\nu' = $ Obtimization Objective Value}
                    \If {$\nu' > \nu$}
                      \State{$\nu \gets \nu'$}
                      \State{$s^\text{new} \gets s$}
                      \State{$c_1^\text{new} \gets c_1$}
                      \State{$c_1^\text{new} \gets c_2$}
                    \EndIf
                  \EndIf
                  \State{$I_s \gets (I_s \setminus \{c_2\}) \cup \{c_1\}$}
                  \State{$I_{c_2} \gets I_{c_2} \setminus \{s\}$}
                  \State{$I_{c_1} \gets I_{c_1} \cup \{s\}$}
                \EndIf
              \EndFor
            \EndFor
            \State{$I_s^\text{new} \gets (I_s^\text{new} \setminus \{c_1^\text{new}\}) \cup \{c_2^\text{new}\}$}
            \State{$I_{c_1}^\text{new} \gets I_{c_1}^\text{new} \setminus \{s^\text{new}\}$}
            \State{$I_{c_2}^\text{new} \gets I_{c_2}^\text{new} \cup \{s^\text{new}\}$}
          \EndWhile
        \end{algorithmic}
      \end{algorithm}
    \end{latin}

    \subsection{بررسی الگوریتم}
      در ابتدای‌شروع الگوریتم نرخ انتخابی همه‌ی سرویس‌ها صفر می‌باشد و هیچ منبع پردازشی اختصاص پیدار نکرده‌است.
      در نتیجه مقدار تابع هدف بهینه سازی $-\sum_{s=1}^N \alpha_s \omega_s R_s$ می‌باشد.
      علاوه براین تابع هدف بهینه‌سازی همواره یک عدد منفی است.
      با در نظر گرفتن این‌که در هر تکرار مقدار تابع هدف حداقل به اندازه‌ی $\epsilon$ افزایش پیدا می‌کند، تعداد تکرار‌های الگوریتم نمی‌تواند بیش از $\sum_{s=1}^N  \alpha_s \omega_s R_s / \epsilon$  باشد.
      
      اگر فرض کنیم در مرحله‌ای دلخواه از این الگوریتم سرویس $s$ به $m$ منبع پردازشی اختصاص پیدار کرده باشد و $m'$ تعداد منابع پردازشی اختصاص پیدا نکردده به سرویس $s$ باشد، باید $(m+1) \times (m'+1) - 1$ بار مسئله بهینه‌سازی حل شود.
      در نتیجه می‌توان نتیجه گرفت که تعداد دفعاتی که مسئله بهینه سازی در هر بار تکرار الگوریتم حل می‌شود، کم‌تر از $N(M+1)^2$ است.
      در نتیجه تعداد دفعاتی که مسئله بهینه سازی در کل الگوریتم حل می‌شود کم‌تر از $N(M+1)^2 \sum_{s=1}^N  \alpha_s \omega_s R_s / \epsilon$ است.
      از این رابطه واضح است که با افزایش $\epsilon$ انتظار می‌رود الگوریتم زود‌تر پایان یابد.

  \section{نتایج شبیه‌سازی}
    برای شبیه سازی این قسمت از محیطی مانند فصل قبل کمک گرفتیم.
    در همه موارد، شبیه سازی‌ها ۵ بار تکرار شده‌اند و نتایج میانگین آورده شده‌است.
    فرض شده‌است که سرویس‌ها و منابع پردازشی به صورت تصادفی در یک دایره با شعاع ۱۰۰ متر پراکنده شده‌اند و توپولوژی شبکه و سایر پارامتر‌ها مانند فصل قبل در نظر گرفته شده‌اند.
    
    فرض می‌کنیم تعداد سرویس‌ها $N=15$ باشد و تعداد منابع پردازشی لبه شبکه ($M$) از ۱۲ تا ۲۰ تغییر کند.
    مطابق فصل قبل دو سناریو با و بدون حظور منبع پردازشی ابری را در نظر می‌گیریم و میانگین هزینه سرویس‌ها($-U/N$) را رسم می‌کنیم.
    انتظار داریم که با افزایش تعداد منابع پردازشی، میانگین هزینه سرویس‌ها کاهش پیدا کند. چرا که قدرت پردازشی بیشتری در شبکه وجود دارد و می‌تواند باعث کاهش تاخیر یا اختلاف نرخ مطلوب و نرخ بهینه شود.

    نتیجه این شبیه‌سازی در \cref{fig:many_to_many:sim6} آوده شده‌است.
    همانطور که در شکل هم مشخص است با افزایش تعداد منابع پردازشی، میانگین هزینه سرویس‌ها کاهشی است.
    علاوه بر این، میانگین هزینه‌ی سرویس‌ها سناریوای که منبع پردازشی ابری در آن وجود داشت، همواره کم‌تر از سناریوی بدون منبع پردازش ابری است.
    هم‌چنین، با افزایش تعداد منابع پردازشی لبه شبکه، اختلاف این دو سناریو کاهش پیدا می‌کند تا در تعداد ۲۰ منبع پردازشی لبه شبکه، تقریبا صفر می‌شود.
    دلیلش آن است که با افزایش منابع پردازشی لبه شبکه همه پردازش‌ها در لبه شبکه انجام شده و تاثیر وجود منبع پردازشی ابری در میانگین هزینه‌ها به صفر می‌رسد.

    \begin{figure}[H]
      \centerline{\includegraphics[width=17cm]{graphics/many_to_many/sim_6}}
      \caption{میانگین هزینه سرویس‌ها در برابر تعداد منابع پردازشی در لبه شبکه}
      \label{fig:many_to_many:sim6}
    \end{figure}

    اثر پارامتر $\beta$ در این روش تخصیص منابع در \cref{fig:many_to_many:sim7} بررسی شده‌است.
    در این شکل اثر $\beta$ روی اختلاف نرخ بهینه و مطلوب و بیشترین تاخیر برای یک سرویس در بازه $\beta\in[30, 70]$ رسم شده‌است.
    همان‌طور که بیان شد $\beta$ نسبت اهمیت تاخیر به اختلاف نرخ بهینه و مطلوب است.
    در نتیجه انتظار داریم با افزایش $\beta$ اختلاف نرخ افزایش پیدا کرده و تاخیر کاهش پیدا کند که شکل هم همین را نشان می‌دهد.
    
    \begin{figure}[]
      \centerline{\includegraphics[width=17cm]{graphics/many_to_many/sim_7}}
      \caption{تاثیر $\beta$ بر تاخیر و اختلاف نرخ بهینه با نرخ مطلوب برای یک سرویس}
      \label{fig:many_to_many:sim7}
    \end{figure}

    \begin{figure}[H]
      \centerline{\includegraphics[width=17cm]{graphics/many_to_many/sim_8}}
      \caption{تاثیر $\alpha$ بر میانگین هزینه سرویس‌ها}
      \label{fig:many_to_many:sim8}
    \end{figure}

  \section{جمع‌بندی و نتیجه‌گیری}
    

